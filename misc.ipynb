{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DECONSTRUCT KEY & VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_value(blob):\n",
    "    key = list(blob)[0]\n",
    "    value = blob[key]\n",
    "    \n",
    "    return key, value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DECISION MACHINE FOR DATASET LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decision_machine():\n",
    "    \n",
    "    # CALIBRATE QUANTILE THRESHOLDS & RETURN NEW LABELS\n",
    "    def calibrate(self, dataframe, settings):\n",
    "        \n",
    "        # GET LABEL LOG RETURN VALUES\n",
    "        labels = self.log_returns(dataframe)\n",
    "        \n",
    "        # SET QUANTILE THRESHOLDS\n",
    "        self.lower = labels.quantile(settings['lower'])\n",
    "        self.upper = labels.quantile(settings['upper'])\n",
    "        \n",
    "        return self.vote(labels)\n",
    "        \n",
    "    # CONVERT & RETURN NEW LABELS\n",
    "    def convert(self, dataframe):\n",
    "        \n",
    "        # GET LABEL LOG RETURN VALUES\n",
    "        labels = self.log_returns(dataframe)\n",
    "        return self.vote(labels)\n",
    "        \n",
    "    # DECIDE LABEL TAG VIA VOTE\n",
    "    def vote(self, labels):\n",
    "        container = []\n",
    "        \n",
    "        # BUY   = 0\n",
    "        # SELL  = 1\n",
    "        # HOLD  = 2\n",
    "        \n",
    "        # LOOP THROUGH LABELS\n",
    "        for label in labels:\n",
    "\n",
    "            # BUY\n",
    "            if (label < self.lower):\n",
    "                container.append(0)\n",
    "\n",
    "            # SELL\n",
    "            elif label > self.upper:\n",
    "                container.append(1)\n",
    "\n",
    "            # HOLD\n",
    "            else:\n",
    "                container.append(2)\n",
    "\n",
    "        return container\n",
    "    \n",
    "    # GET LOG RETURN VALUE DF COLUMN\n",
    "    def log_returns(self, dataframe):\n",
    "        return np.log(dataframe['label'] / dataframe['label'].shift(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLONE DATAFRAME & REPLACE LABEL COLUMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_labels(old_dataframe, labels):\n",
    "    \n",
    "    # CLONE & REPLACE\n",
    "    dataframe = old_dataframe.copy()\n",
    "    dataframe['label'] = labels\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RENAME DICT KEYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_settings(old_settings):\n",
    "    new_settings = {}\n",
    "    \n",
    "    for key in old_settings.keys():\n",
    "        new_settings['model__' + key] = old_settings[key]\n",
    "        \n",
    "    return new_settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BALANCE PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_predictions(predictions):\n",
    "    collection = []\n",
    "    \n",
    "    # LOOP THROUGH PREDICTIONS & CHECK LENGTHS\n",
    "    for values in predictions.values():\n",
    "        collection.append(len(values))\n",
    "    \n",
    "    # FIND THE SMALLEST SIZE\n",
    "    smallest =  min(collection)\n",
    "    \n",
    "    # CUT OFF EXTRA ELEMENTS\n",
    "    for key in predictions.keys():\n",
    "        predictions[key] = predictions[key][-smallest:]\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRAPH FITTING MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_mse(data):\n",
    "    plt.plot(data)\n",
    "    plt.ylabel('mean squared error')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE TRAIN & TEST CONFUSION MATRIXES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_matrixes(label_table, classifier_table):\n",
    "    container = {}\n",
    "    \n",
    "    # TRUE LABELS\n",
    "    matrix_labels = label_table['label'].to_numpy()\n",
    "    \n",
    "    # LOOP THROUGH THE COLUMNS\n",
    "    for column in classifier_table.columns:\n",
    "    \n",
    "        # MODEL PREDICTIONS\n",
    "        predictions = classifier_table[column].to_numpy()\n",
    "\n",
    "        # CREATE A CONFUSION MATRIX\n",
    "        matrix = confusion_matrix(\n",
    "            matrix_labels,\n",
    "            predictions,\n",
    "            labels=[0, 1, 2]\n",
    "        )\n",
    "\n",
    "        # PUSH IT TO THE CONTAINER\n",
    "        container[column] = {\n",
    "            'training': {\n",
    "                'graph': 'matrix',\n",
    "                'data': matrix.tolist()\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    return container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_matrixes(container, prediction_table, labels):\n",
    "    \n",
    "    # LOOP THROUGH PREDICTION COLUMNS\n",
    "    for column in prediction_table.columns:\n",
    "    \n",
    "        # MODEL PREDICTIONS\n",
    "        predictions = prediction_table[column].to_numpy()\n",
    "\n",
    "        # CREATE A CONFUSION MATRIX\n",
    "        matrix = confusion_matrix(\n",
    "            labels,\n",
    "            predictions,\n",
    "            labels=[0, 1, 2]\n",
    "        )\n",
    "\n",
    "        # PUSH IT TO THE MATRIX CONTAINER\n",
    "        container[column]['validation'] = {\n",
    "            'graph': 'matrix',\n",
    "            'data': matrix.tolist()\n",
    "        }\n",
    "    \n",
    "    return container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REGRESSION FITTING METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_fitting_metrics(regression_ensemble):\n",
    "    \n",
    "    # STITCH TOGETHER REGRESSION FITTING METRICS\n",
    "    fitting = {}\n",
    "    \n",
    "    for blob in regression_ensemble.models:\n",
    "        collection = {}\n",
    "        for index, model in enumerate(blob):\n",
    "\n",
    "            # DEFAULT BAR TYPE\n",
    "            bar_type = 'line'\n",
    "\n",
    "            # IF THE SCORE HAS A R2 PROPERTY\n",
    "            if 'R2' in model.score:\n",
    "\n",
    "                # CHANGE BAR TYPE\n",
    "                bar_type = 'bar'\n",
    "\n",
    "                # ADD THE SUB-PROPERTIES IF THEY DONT ALREADY EXIST\n",
    "                if 'R2' not in collection:\n",
    "                    for key in model.score.keys():\n",
    "                        collection[key] = {}\n",
    "\n",
    "                # LOOP IN VALUES\n",
    "                for key in model.score.keys():\n",
    "                    collection[key]['fold_' + str(index)] = model.score[key]\n",
    "\n",
    "            # OTHERWISE, INJECT NORMALLY\n",
    "            else:\n",
    "                collection['fold_' + str(index)] = model.score\n",
    "\n",
    "        fitting[model.name] = {\n",
    "            'graph': bar_type,\n",
    "            'data': collection\n",
    "        }\n",
    "        \n",
    "    return fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
