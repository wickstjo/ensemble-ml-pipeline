{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynb.fs.full.processing as processing\n",
    "import ipynb.fs.full.training as training\n",
    "import ipynb.fs.full.storage as storage\n",
    "import ipynb.fs.full.misc as misc\n",
    "import ipynb.fs.full.splitting as splitting\n",
    "import ipynb.fs.full.features as features\n",
    "import ipynb.fs.full.ensemble as ensemble\n",
    "import ipynb.fs.full.profit as profit\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE REGRESSION DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_regression_dataset(config):\n",
    "    \n",
    "    # CRATE BASELINE DATAFRAME\n",
    "    dataframe = processing.create_dataframe(config)\n",
    "    \n",
    "    # ADD TYPE FEATURES\n",
    "    regression_dataset = features.add(dataframe, config['features'])\n",
    "    \n",
    "    return regression_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN & VALIDATE PIPELINE ENSEMBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(config):\n",
    "    \n",
    "    # CREATE REGRESSION DATASET\n",
    "    regression_dataset = create_regression_dataset(config)\n",
    "    \n",
    "    # DROP THE CLOSE PRICE COLUMN\n",
    "    regression_dataset.drop(columns=['close'], inplace=True)\n",
    "    \n",
    "    # SPLIT INTO TRAIN & TEST DATASETS\n",
    "    primary_dataset = splitting.general(\n",
    "        regression_dataset,\n",
    "        config['splitting']['train_split']\n",
    "    )\n",
    "    \n",
    "    # PRINT MSG\n",
    "    print('\\n### START TRAINING REGRESSION ENSEMBLE\\n')\n",
    "    \n",
    "    # TRAIN THE REGRESSION ENSEMBLE\n",
    "    regression_ensemble, regression_table = ensemble.regression(primary_dataset, config)\n",
    "    \n",
    "    # CREATE A DECISION MACHINE\n",
    "    decision_machine = misc.decision_machine()\n",
    "    \n",
    "    # PUT REGRESSION LABELS THROUGH IT\n",
    "    regression_labels = decision_machine.calibrate(\n",
    "        regression_table,\n",
    "        config['classification_ensemble']['decision']\n",
    "    )\n",
    "    \n",
    "    # REPLACE OLD LABELS WITH NEW ONES\n",
    "    labeled_regression_table = misc.replace_labels(\n",
    "        regression_table,\n",
    "        regression_labels\n",
    "    )\n",
    "    \n",
    "    # PRINT MSG\n",
    "    print('\\n### START TRAINING CLASSIFIER ENSEMBLE\\n')\n",
    "    \n",
    "    # TRAIN THE CLASSIFIER ENSEMBLE\n",
    "    classifier_ensemble, classifier_table = ensemble.classifier(\n",
    "        labeled_regression_table,\n",
    "        config\n",
    "    )\n",
    "    \n",
    "    # CREATE A CONFUSION MATRIX FOR TRAIN PREDICTIONS\n",
    "    classifier_matrixes = misc.train_matrixes(\n",
    "        labeled_regression_table,\n",
    "        classifier_table\n",
    "    )\n",
    "    \n",
    "    # PRINT MSG\n",
    "    print('\\n### PERFORMING VALIDATION')\n",
    "    \n",
    "    # CREATE VALIDATION DATASET WITH REGRESSION ENSEMBLE PREDICTIONS\n",
    "    validation_dataset = regression_ensemble.predict(primary_dataset['test'])\n",
    "    \n",
    "    # CLONE DATASET & ADD LABELS\n",
    "    validation_with_labels = validation_dataset.copy()\n",
    "    validation_with_labels['label'] = primary_dataset['test']['labels'][-len(validation_dataset):]\n",
    "    \n",
    "    # PREDICT WITH THE CLASSIFIER ENSEMBLE\n",
    "    classifier_predictions = classifier_ensemble.predict({\n",
    "        'features': validation_dataset.to_numpy(),\n",
    "        'labels': []\n",
    "    })\n",
    "    \n",
    "    # PUT TRUE LABELS THROUGH DECISION MACHINE\n",
    "    matrix_labels = decision_machine.convert(validation_with_labels)\n",
    "    \n",
    "    # CREATE A CONFUSION MATRIX FOR VALIDATION PREDICTIONS\n",
    "    classifier_matrixes = misc.validation_matrixes(\n",
    "        classifier_matrixes,\n",
    "        classifier_predictions,\n",
    "        matrix_labels\n",
    "    )\n",
    "    \n",
    "    # STITCH TOGETHER REGRESSION FITTING METRICS\n",
    "    regression_fitting = misc.regression_fitting_metrics(regression_ensemble)\n",
    "    \n",
    "    # PRINT MSG\n",
    "    print('### SAVING PIPELINE')\n",
    "    \n",
    "    # SAVE EVERYTHING\n",
    "    pipeline_name = storage.save_pipeline({\n",
    "        'config': config,\n",
    "        'regression_ensemble': regression_ensemble,\n",
    "        'classifier_ensemble': classifier_ensemble,\n",
    "        'predictions': {\n",
    "            'regression': {\n",
    "                'training': {\n",
    "                    'graph': 'line',\n",
    "                    'data': json.loads(regression_table.to_json())\n",
    "                },\n",
    "                'validation': {\n",
    "                    'graph': 'line',\n",
    "                    'data': json.loads(validation_with_labels.to_json())\n",
    "                }\n",
    "            },\n",
    "            'classifiers': classifier_matrixes\n",
    "        },\n",
    "        'regression_fitting': regression_fitting\n",
    "    })\n",
    "    \n",
    "    # PRINT MSG\n",
    "    print('### FINISHED\\n')\n",
    "\n",
    "    return pipeline_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD & PREDICT WITH PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_pipeline(name, config):\n",
    "    \n",
    "    # PRINT MSG\n",
    "    print('\\n### SERIALIZING PIPELINE\\n')\n",
    "    \n",
    "    # SERIALIZE THE REGRESSION & CLASSIFIER ENSEMBLE\n",
    "    regression_ensemble, classifier_ensemble, pipeline_config = storage.load_pipeline(name)\n",
    "    \n",
    "    # REPLACE OLD DATASET\n",
    "    pipeline_config['data'] = config['data'] # 'C://Users/35840/desktop/coding/python/pipeline/extra/fresh.csv'\n",
    "    \n",
    "    # PRINT MSG\n",
    "    print('\\n### CREATING REGRESSION DATASET')\n",
    "    \n",
    "    # ADD FEATURES & CREATE REGRESSION DATASET\n",
    "    regression_dataset = create_regression_dataset(pipeline_config)\n",
    "    \n",
    "    # DROP LABEL COLUMN & POP CLOSE COLUMN\n",
    "    regression_dataset.drop(columns=['label'], inplace=True)\n",
    "    closing_prices = regression_dataset.pop('close')\n",
    "    \n",
    "    # PRINT MSG\n",
    "    print('### CREATING CLASSIFIER DATASET')\n",
    "    \n",
    "    # PREDICT WITH REGRESSION ENSEMBLE\n",
    "    regression_predictions = regression_ensemble.predict({\n",
    "        'features': regression_dataset.to_numpy(),\n",
    "        'labels': [0] * len(regression_dataset)\n",
    "    })\n",
    "    \n",
    "    # PRINT MSG\n",
    "    print('### PREDICTING VALUES')\n",
    "    \n",
    "    # PREDICT WITH CLASSIFIER ENSEMBLE\n",
    "    classifier_predictions = classifier_ensemble.predict({\n",
    "        'features': regression_predictions.to_numpy(),\n",
    "        'labels': []\n",
    "    })\n",
    "    \n",
    "    # PRINT MSG\n",
    "    print('### CALCULATING PROFIT/LOSS')\n",
    "    \n",
    "    # ATTACH CLOSING PRICE TO PREDICTIONS\n",
    "    classifier_predictions['close'] = closing_prices.to_numpy()[-len(classifier_predictions):]\n",
    "    \n",
    "    # RUN PREDICTIONS THROUGH A HEURISTIC PROFIT CALC\n",
    "    profit_metric = profit.weighted_position_investing(\n",
    "        classifier_predictions,\n",
    "        config\n",
    "    )\n",
    "    \n",
    "    # PRINT MSG\n",
    "    print('### SAVING PREDICTION')\n",
    "    \n",
    "    # SAVE THE PROFIT METRIC\n",
    "    pred_name = storage.save_prediction(name, profit_metric)\n",
    "    \n",
    "    # PRINT MSG\n",
    "    print('### FINISHED\\n')\n",
    "    \n",
    "    # PARSE AS JSON & RETURN\n",
    "    return pred_name, profit_metric.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTING CREATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_config = storage.load_yaml('configs/train_config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regression_dataset = create_regression_dataset(train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#name = create_pipeline(train_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTING USAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_config = storage.load_yaml('configs/pred_config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#foob = use_pipeline('PIPELINE-1603544359', pred_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#foob.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prof = profit.weighted_position_investing(foob, pred_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#foo = prof.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
